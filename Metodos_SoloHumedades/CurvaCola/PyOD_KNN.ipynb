{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyOD - IsolationForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos librerías y datos:\n",
    "\n",
    "Las típicas (pandas, matplotlib, numpy)...\n",
    "\n",
    "Funciones de sklearn de preprocesado y métricas.\n",
    "\n",
    "Modelos y métricas de PyOD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FibraticPredNIRHumedadPV</th>\n",
       "      <th>Hum_Pred</th>\n",
       "      <th>Etapa2MWHumedadPV</th>\n",
       "      <th>Negro</th>\n",
       "      <th>CurvaCola</th>\n",
       "      <th>Congelado</th>\n",
       "      <th>Hum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fecha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-10 10:00:00</th>\n",
       "      <td>-6.465569</td>\n",
       "      <td>-10.920920</td>\n",
       "      <td>-13.141570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-10 10:01:00</th>\n",
       "      <td>-6.355772</td>\n",
       "      <td>-10.604865</td>\n",
       "      <td>-12.412745</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FibraticPredNIRHumedadPV   Hum_Pred  Etapa2MWHumedadPV  \\\n",
       "fecha                                                                         \n",
       "2021-02-10 10:00:00                 -6.465569 -10.920920         -13.141570   \n",
       "2021-02-10 10:01:00                 -6.355772 -10.604865         -12.412745   \n",
       "\n",
       "                     Negro  CurvaCola  Congelado  Hum  \n",
       "fecha                                                  \n",
       "2021-02-10 10:00:00      1          0          1    0  \n",
       "2021-02-10 10:01:00      1          0          1    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Datasets/Dataset_2.csv',index_col='fecha', usecols=['fecha','FormacionNIRHumedadPV', 'FibraticPredNIRHumedadPV', 'Hum_Pred',\n",
    "       'Etapa2MWHumedadPV','Negro', 'CurvaCola', 'Congelado', 'Hum'])\n",
    "df['FibraticPredNIRHumedadPV'] = df['FormacionNIRHumedadPV'] - df['FibraticPredNIRHumedadPV']\n",
    "df['Hum_Pred'] = df['FormacionNIRHumedadPV'] - df['Hum_Pred']\n",
    "df['Etapa2MWHumedadPV'] = df['FormacionNIRHumedadPV'] - df['Etapa2MWHumedadPV']\n",
    "df = df.drop(['FormacionNIRHumedadPV'], axis=1)\n",
    "#df = df.loc[:,['Diferencia','Negro', 'CurvaCola', 'Congelado', 'Hum']]\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todas las anomalías en una columna, para posteriormente realizar las métricas tanto para todas las anomalías como para cada una en concreto.\n",
    "\n",
    "Para ello, sumo las columnas de anomalías, y después las que son mayores que cero las establezco como uno (porque significa que alguna de las columnas si tenía anomalía registrada), las demás como cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Anomalia'] = df['Negro'] + df['Congelado'] + df['Hum']\n",
    "df['Anomalia'] = df['Anomalia'].map(lambda x: 1 if x!=0 else 0)\n",
    "\n",
    "df = df.drop(df[df['Anomalia']==1].index)\n",
    "df = df.drop(['Negro','Congelado','Hum','Anomalia'], axis=1)\n",
    "\n",
    "lista_anomalias = ['CurvaCola']\n",
    "\n",
    "atributos = df.columns.drop(lista_anomalias)\n",
    "len(atributos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escogemos un subconjunto del dataset para entrenamientos más cortos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.iloc[3000:60000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo conjuntos de train, validation y test, y estandarizo:\n",
    "\n",
    "Separo los atributos en X y las anomalias en Y. De esta manera, al realizar el train_test_split, se mantendrán las proporciones de cada anomalía, con muestreos temporales aleatorios.\n",
    "\n",
    "Primero separo en train-test (80-20) y después separo el test en test-validation (50-50), para así obtener finalmente train-validation-test (80-10-10).\n",
    "\n",
    "Una vez separado, entreno el StandardScaler() con el conjunto de entrenamiento, y se lo aplico al conjunto de validación y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo los atributos para el entrenamiento de la salida\n",
    "X = df.loc[:, atributos]\n",
    "Y = df.loc[:, lista_anomalias]\n",
    "\n",
    "#Calculo la proporcion de outliers presentes\n",
    "proporcion_outliers = round(np.count_nonzero(Y) / len(Y),3)\n",
    "\n",
    "#Separo entrenamiento y test (80-20)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = random_state)\n",
    "\n",
    "#Normalizo\n",
    "standarizer = StandardScaler()\n",
    "standarizer.fit(X_train)\n",
    "X_train_standarized = standarizer.transform(X_train)\n",
    "X_test_standarized = standarizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, establezco primero la lista de hiperparámetros a entrenar y la de métricas a analizar.\n",
    "\n",
    "creo dos arrays de ceros, uno para las scores y otro para las labels.\n",
    "\n",
    "Realizo un bucle, estableciendo un entrenamiento por cada hiperparámetro.\n",
    "\n",
    "Después, extraigo scores y labels, almacenándolas en un array, y calculo las métricas, haciendo lo mismo. Una vez termina el bucle, estos dos vectores los paso a un dataframe para su visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo:  6.5134\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "#Establecemos parametros\n",
    "metricas_list = ['roc_auc','accuracy','precision','kappa','sensibilidad','especificidad']\n",
    "anomalia = 'CurvaCola'\n",
    "\n",
    "#Entrenamiento\n",
    "n = 500\n",
    "clf = KNN(n_jobs=-1)\n",
    "clf.fit(X_train_standarized)\n",
    "\n",
    "#Prediccion\n",
    "Y_pred = clf.predict(X_test_standarized)\n",
    "\n",
    "#Metricas\n",
    "roc_auc = roc_auc_score(Y_test[anomalia], Y_pred)\n",
    "accuracy = accuracy_score(Y_test[anomalia],Y_pred)\n",
    "precision = precision_score(Y_test[anomalia],Y_pred)\n",
    "kappa = cohen_kappa_score(Y_test[anomalia],Y_pred)\n",
    "sensibilidad = recall_score(Y_test[anomalia],Y_pred)\n",
    "especificidad = recall_score(Y_test[anomalia],Y_pred, pos_label=0)\n",
    "\n",
    "valores = [roc_auc,accuracy,precision,kappa,sensibilidad,especificidad]\n",
    "metricas = pd.DataFrame(valores)\n",
    "metricas.index = metricas_list\n",
    "metricas.columns = [anomalia]\n",
    "\n",
    "#Tiempo\n",
    "t1 = time()\n",
    "duration = round(t1 - t0, ndigits=4)\n",
    "print('Tiempo: ', duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizo las métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>kappa</th>\n",
       "      <th>sensibilidad</th>\n",
       "      <th>especificidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CurvaCola</th>\n",
       "      <td>0.486957</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>0.067289</td>\n",
       "      <td>-0.024485</td>\n",
       "      <td>0.077026</td>\n",
       "      <td>0.896889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            roc_auc  accuracy  precision     kappa  sensibilidad  \\\n",
       "CurvaCola  0.486957  0.824684   0.067289 -0.024485      0.077026   \n",
       "\n",
       "           especificidad  \n",
       "CurvaCola       0.896889  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test['Y_pred'] = Y_pred\n",
    "Y_test.to_csv('Resultados/PyOD_KNN_completo.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "084e8b912a56bf1ec199b7cc8c30ae9313a998703506b070bededcac63d0da25"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
